{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7356c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim, distributions\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from batch_norm_note import BatchNormLayer\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a354b",
   "metadata": {},
   "source": [
    "# The model of Real NVPÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f84283",
   "metadata": {},
   "source": [
    "Base distribution : $Z$.<br>\n",
    "Target Distribution: $X$.<br>\n",
    "Flow $f = f_n \\circ f_{n-1} \\circ f_{n-2}\\cdots f_1$ <br>\n",
    "$Z = f(X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66392d3",
   "metadata": {},
   "source": [
    "# Implement the coupling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e5e0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CouplingLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hid_dim, mask):\n",
    "        super().__init__()\n",
    "        self.s_fc1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.s_fc2 = nn.Linear(hid_dim, hid_dim)\n",
    "        self.s_fc3 = nn.Linear(hid_dim, output_dim)\n",
    "        self.t_fc1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.t_fc2 = nn.Linear(hid_dim, hid_dim)\n",
    "        self.t_fc3 = nn.Linear(hid_dim, output_dim)\n",
    "        self.mask = mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_m = x * self.mask\n",
    "        s_out = torch.tanh(self.s_fc3(F.relu(self.s_fc2(F.relu(self.s_fc1(x_m))))))\n",
    "        t_out = self.t_fc3(F.relu(self.t_fc2(F.relu(self.t_fc1(x_m)))))\n",
    "        y = x_m + (1-self.mask)*(x*torch.exp(s_out)+t_out)\n",
    "        log_det_jacobian = s_out.sum(dim=1)\n",
    "        return y, log_det_jacobian\n",
    "\n",
    "    def backward(self, y):\n",
    "        y_m = y * self.mask\n",
    "        s_out = torch.tanh(self.s_fc3(F.relu(self.s_fc2(F.relu(self.s_fc1(y_m))))))\n",
    "        t_out = self.t_fc3(F.relu(self.t_fc2(F.relu(self.t_fc1(y_m)))))\n",
    "        x = y_m + (1-self.mask)*(y-t_out)*torch.exp(-s_out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a392dffe",
   "metadata": {},
   "source": [
    "Suppose $X$ and $Z$ all have D dimensions. I mask d\n",
    "For the forward function above, we use the formula below:<br>\n",
    "$z_{1:d} = x_{1:d}$ <br>\n",
    "$z_{d+1: D} = x_{d+1:D}\\odot exp(s(x_{1:d})) + t(x_{1:d})$<br>\n",
    "<br>\n",
    "\n",
    "Get the determinant contributed by this transformation: $exp(s(x_{1:d}))$\n",
    "\n",
    "Backward function is using the formula below:<br>\n",
    "$x_{1:d} = z_{1:d}$ <br>\n",
    "$x_{d+1:D} = (z_{d+1:D} - t(z_{1:d}))\\odot exp(-s(z_{1:d}))$ <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "deb0369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hid_dim, mask, n_layers = 6):\n",
    "        super().__init__()\n",
    "        assert n_layers >= 2, 'num of coupling layers should be greater or equal to 2'\n",
    "\n",
    "        self.modules = []\n",
    "        \n",
    "        self.modules.append(CouplingLayer(input_dim, output_dim, hid_dim, mask))\n",
    "        self.modules.append(BatchNormLayer(input_dim))\n",
    "        \n",
    "        for _ in range(n_layers-2):\n",
    "            mask = 1 - mask\n",
    "            self.modules.append(CouplingLayer(input_dim, output_dim, hid_dim, mask))\n",
    "            self.modules.append(BatchNormLayer(input_dim))\n",
    "            \n",
    "        self.modules.append(CouplingLayer(input_dim, output_dim, hid_dim, 1 - mask))\n",
    "        self.modules.append(BatchNormLayer(input_dim))\n",
    "        \n",
    "        self.module_list = nn.ModuleList(self.modules)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #ldj_sum = 0 # sum of log determinant of jacobian\n",
    "        ldj_sum = torch.zeros(x.shape[0])\n",
    "        for module in self.module_list:\n",
    "            x, ldj= module(x)\n",
    "            ldj_sum += ldj\n",
    "        return x, ldj_sum\n",
    "\n",
    "    def backward(self, z):\n",
    "        #ldj_sum = 0 # sum of log determinant of jacobian\n",
    "        ldj_sum = torch.zeros(z.shape[0])\n",
    "        for module in reversed(self.module_list):\n",
    "            z, ldj = module.backward(z)\n",
    "            ldj_sum += ldj\n",
    "        return z, ldj_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114418ee",
   "metadata": {},
   "source": [
    "Sum of the log determinant of jacobian for each layer:\n",
    "$\\sum_j s_j(x_{1:d})$.<br>\n",
    "\n",
    "What we should note here is that the compnent which is identical in 1 transformation will be modified in the next transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c96179d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training Data Creation\n",
    "'''\n",
    "\n",
    "'''\n",
    "Generating twelve independent normal distribution\n",
    "'''\n",
    "a = torch.zeros(12)\n",
    "b = torch.tensor([1,2,4,1,2,4,1,2,2,2,2,2])\n",
    "s_dist = distributions.Normal(a, b)\n",
    "sample_normal = s_dist.sample(torch.Size([60000]))\n",
    "\n",
    "\n",
    "'''\n",
    "Generate the sample of X\n",
    "'''\n",
    "sample_X = sample_normal[:,0].pow(2)\n",
    "for i in range(1,8):\n",
    "    sample_X = torch.column_stack((sample_X,sample_normal[:,i].pow(2)))\n",
    "\n",
    "sample_X = torch.column_stack((sample_X, sample_normal[:,8].pow(2) \n",
    "                               + sample_normal[:,9].pow(2)))\n",
    "sample_X = torch.column_stack((sample_X, sample_normal[:,10].pow(2) \n",
    "                               + sample_normal[:,11].pow(2)))\n",
    "\n",
    "\n",
    "'''\n",
    "Load Data\n",
    "'''\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {}\n",
    "train_loader = torch.utils.data.DataLoader(sample_X, batch_size=500, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe1e59b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test data\n",
    "This data is used to test the accuracy of our model\n",
    "'''\n",
    "\n",
    "test_normal = s_dist.sample(torch.Size([1000]))\n",
    "\n",
    "test_X = test_normal[:,0].pow(2)\n",
    "for i in range(1,8):\n",
    "    test_X = torch.column_stack((test_X, test_normal[:,i].pow(2)))\n",
    "\n",
    "test_X = torch.column_stack((test_X, test_normal[:,8].pow(2) \n",
    "                               + test_normal[:,9].pow(2)))\n",
    "test_X = torch.column_stack((test_X, test_normal[:,10].pow(2) \n",
    "                               + test_normal[:,11].pow(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e99b31",
   "metadata": {},
   "source": [
    "Each component of data is independent from other components:\n",
    "$[X_1, X_2, X_3, X_4, X_5, X_6, X_7, X_8, X_9, X_{10}]$<br>\n",
    "$X_1, X_4, X_7 \\sim Gamma(\\frac{1}{2}, \\frac{1}{2}) $ <br>\n",
    "$X_2, X_5, X_8 \\sim Gamma(\\frac{1}{2}, \\frac{1}{8})$<br>\n",
    "$X_3, X_6 \\sim Gamma(\\frac{1}{2}, \\frac{1}{32})$ <br>\n",
    "$X_9, X_{10} \\sim Gamma(1, \\frac{1}{8})$ <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00f97db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "LOG_INTERVAL = 50\n",
    "EPOCHS = 15\n",
    "INPUT_DIM = 10\n",
    "OUTPUT_DIM = 10\n",
    "HIDDEN_DIM = 256\n",
    "N_COUPLE_LAYERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de57557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.from_numpy(np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1]).astype(np.float32))\n",
    "model = RealNVP(INPUT_DIM, OUTPUT_DIM, HIDDEN_DIM, mask, N_COUPLE_LAYERS)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "prior_z = distributions.MultivariateNormal(torch.zeros(10), torch.eye(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff6c6c",
   "metadata": {},
   "source": [
    "# Training the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e300357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        z, log_det_j_sum = model(data)\n",
    "        loss = -(prior_z.log_prob(z)+log_det_j_sum).mean()\n",
    "        loss.backward()\n",
    "        cur_loss = loss.item()\n",
    "        train_loss += cur_loss\n",
    "        optimizer.step()\n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100.*batch_idx / len(train_loader),\n",
    "                cur_loss/len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, train_loss / len(train_loader.dataset)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bda0175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.065833\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.013500\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.012697\n",
      "====> Epoch: 1 Average loss: 0.0166\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.012101\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.011315\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.011728\n",
      "====> Epoch: 2 Average loss: 0.0118\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.011621\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.011790\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.010959\n",
      "====> Epoch: 3 Average loss: 0.0113\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.010748\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.010696\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.011307\n",
      "====> Epoch: 4 Average loss: 0.0110\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.010165\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.010120\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.010912\n",
      "====> Epoch: 5 Average loss: 0.0107\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.011093\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.010316\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.010497\n",
      "====> Epoch: 6 Average loss: 0.0106\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.010221\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.010761\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.010296\n",
      "====> Epoch: 7 Average loss: 0.0104\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.010729\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.010310\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.010349\n",
      "====> Epoch: 8 Average loss: 0.0103\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.010711\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.010330\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.009771\n",
      "====> Epoch: 9 Average loss: 0.0102\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.010390\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.010445\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.009747\n",
      "====> Epoch: 10 Average loss: 0.0101\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.010105\n",
      "Train Epoch: 11 [25000/60000 (42%)]\tLoss: 0.010175\n",
      "Train Epoch: 11 [50000/60000 (83%)]\tLoss: 0.009819\n",
      "====> Epoch: 11 Average loss: 0.0101\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.010001\n",
      "Train Epoch: 12 [25000/60000 (42%)]\tLoss: 0.010444\n",
      "Train Epoch: 12 [50000/60000 (83%)]\tLoss: 0.010036\n",
      "====> Epoch: 12 Average loss: 0.0100\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.009710\n",
      "Train Epoch: 13 [25000/60000 (42%)]\tLoss: 0.009677\n",
      "Train Epoch: 13 [50000/60000 (83%)]\tLoss: 0.010116\n",
      "====> Epoch: 13 Average loss: 0.0099\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.009556\n",
      "Train Epoch: 14 [25000/60000 (42%)]\tLoss: 0.009141\n",
      "Train Epoch: 14 [50000/60000 (83%)]\tLoss: 0.009222\n",
      "====> Epoch: 14 Average loss: 0.0098\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.009830\n",
      "Train Epoch: 15 [25000/60000 (42%)]\tLoss: 0.010631\n",
      "Train Epoch: 15 [50000/60000 (83%)]\tLoss: 0.009768\n",
      "====> Epoch: 15 Average loss: 0.0097\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58261d9",
   "metadata": {},
   "source": [
    "# Test my results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd58c880",
   "metadata": {},
   "source": [
    "Compare the accurate log probability of X with my estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce2337c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma_147 = torch.distributions.Gamma(1/2, 1/2, validate_args=None)\n",
    "Gamma_258 = torch.distributions.Gamma(1/2, 1/8, validate_args=None)\n",
    "Gamma_36 = torch.distributions.Gamma(1/2, 1/32, validate_args=None)\n",
    "Gamma_910 = torch.distributions.Gamma(1, 1/8, validate_args=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e365b0b1",
   "metadata": {},
   "source": [
    "Use the property of independent of random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b130353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accurate log probability:\n",
    "Log_prob_correct = ( Gamma_147.log_prob(test_X[:,0]) + Gamma_147.log_prob(test_X[:,3]) + Gamma_147.log_prob(test_X[:,6])\n",
    "                   + Gamma_258.log_prob(test_X[:, 1]) + Gamma_258.log_prob(test_X[:, 4]) + Gamma_258.log_prob(test_X[:, 7])\n",
    "                    + Gamma_36.log_prob(test_X[:,2]) + Gamma_36.log_prob(test_X[:,5])\n",
    "                     + Gamma_910.log_prob(test_X[:, 8]) +  Gamma_910.log_prob(test_X[:, 9]) )\n",
    "\n",
    "prob_1 = torch.exp(Log_prob_correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54927355",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting batch stats for validation\n",
      "setting batch stats for validation\n",
      "setting batch stats for validation\n",
      "setting batch stats for validation\n"
     ]
    }
   ],
   "source": [
    "#Log probability of my estimation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "         z_val, Log_Det = model.forward(test_X)\n",
    "         Log_prob_est = prior_z.log_prob(z_val) + Log_Det\n",
    "        \n",
    "prob_2 = torch.exp(Log_prob_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47cc801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12291.9609)\n"
     ]
    }
   ],
   "source": [
    "#Calculating the KL divergence value\n",
    "KL_divergence =(prob_2 * (Log_prob_est - Log_prob_correct)).sum()\n",
    "print(KL_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51dd5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawing the graph\n",
    "base_class = distributions.Normal(torch.zeros(10), torch.ones(10))\n",
    "draw_sample = base_class.sample(torch.Size([5000]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "81e344a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generated data from our model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "      Generated_data, Log_det_I = model.forward(draw_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1052ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_3 = Generated_data[:,2].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "90821d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x106d1beb0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(X_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf135f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_258 = Gamma_910.sample(torch.Size([3000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d6f64f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x108bd59a0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(sample_258)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e210a24e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
